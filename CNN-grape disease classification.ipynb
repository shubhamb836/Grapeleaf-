{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bee327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c6e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS=3\n",
    "EPOCHS=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbcaac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5241 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Grape\",\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c68ec04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb35e5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grape___Black_rot',\n",
       " 'Grape___Esca_(Black_Measles)',\n",
       " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
       " 'Grape___healthy',\n",
       " 'yelllow']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = dataset.class_names\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f2356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eaddb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isfile() is used to check whether it is a file or directory\n",
    "# os.scandir() is a function used to get names of both files and directory in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba573ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\MIT\\\\Sem-2\\\\Mini Project\\\\data set\\\\Grape\\\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12048/2932882429.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdir_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'E:\\MIT\\Sem-2\\Mini Project\\data set\\Grape\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:\\\\MIT\\\\Sem-2\\\\Mini Project\\\\data set\\\\Grape\\\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot)'"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "dir_path = r'E:\\MIT\\Sem-2\\Mini Project\\data set\\Grape\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot)'\n",
    "for path in os.scandir(dir_path):\n",
    "    if path.is_file(): \n",
    "        count += 1\n",
    "print('file count for leaf blight disease:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115fdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dir_path = r'E:\\MIT\\Sem-2\\Mini Project\\data set\\Grape\\Grape___Esca_(Black_Measles)'\n",
    "for path in os.scandir(dir_path):\n",
    "    if path.is_file():\n",
    "        count += 1\n",
    "print('file count for Esca disease:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dir_path = r'E:\\MIT\\Sem-2\\Mini Project\\data set\\Grape\\Grape___Black_rot'\n",
    "for path in os.scandir(dir_path):\n",
    "    if path.is_file():\n",
    "        count += 1\n",
    "print('file countfor black rot disease:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1453016",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dir_path = r'E:\\MIT\\Sem-2\\Mini Project\\data set\\Grape\\Grape___healthy'\n",
    "for path in os.scandir(dir_path):\n",
    "    if path.is_file():\n",
    "        count += 1\n",
    "print('file countfor healthy leaves:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac18a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dir_path = r'E:\\MIT\\Sem-2\\Mini Project\\data set\\Grape\\yelllow'\n",
    "for path in os.scandir(dir_path):\n",
    "    if path.is_file():\n",
    "        count += 1\n",
    "print('file count for sunlight deficiency:', count)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bfc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#80% -> training\n",
    "#20% ->  10% validation and 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data for training\n",
    "train_size = 0.8\n",
    "len(dataset)*train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data for training\n",
    "train_ds = dataset.take(126)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skiping training data that will give test data\n",
    "\n",
    "test_ds = dataset.skip(126)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d27542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation size is 0.1(10%)\n",
    "val_size = 0.1\n",
    "len(dataset)*val_size\n",
    "# no. of photos for validation per Batch or EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = test_ds.take(15)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.skip(15)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function performs above task ( splits dataset into training , testing and validation)\n",
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    ds_size = len(ds)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e498c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda48700",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16394514",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56fe846",
   "metadata": {},
   "source": [
    "## Cache, Shuffle, and Prefetch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c98c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cashing -> it will read the image form the disk and then for the next iteration when you need the same image it will keep that image in memory\n",
    "            #this improves the performance of pipeine\n",
    "# shuffle -> shuffle the images\n",
    "# prefatch -> if you are using gpu and cpu if gpu is busy in training prefatch will load the next set of batch from the disk that will improve the performance\n",
    "# Autotune -> tensorflow determines how many batches to load while GPU is training\n",
    "\n",
    "# due to this training will Fast   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd89fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153ae1f",
   "metadata": {},
   "source": [
    "# Model Builiding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e19b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting image from RGB to gray scale and then changing the resolution of the image to 256 * 256\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "  layers.experimental.preprocessing.Rescaling(1.0/255),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d59d15",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "### Data Augmentation is needed when we have less data, this boosts the accuracy of our model by augmenting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee58aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the image is rotated or different in contrast then your model will not perfrom better so we using data augmentation\n",
    "\n",
    "# data augmentation => to identify  unknown entry like rotated image , different conrast, verticalllyn rotated, horizontally flippped\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf158156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying data augmentation to the training data and prefetching the augmented data to improve training performance.\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bce7e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e4b5147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               14745728  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,839,621\n",
      "Trainable params: 14,839,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809a708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52f100bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37a421de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12048/673040194.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m history = model.fit(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1,\n",
    "    epochs=EPOCHS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1af4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc97959",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9320ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730fa7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting class of image\n",
    "#we are doing shuffling hence image is/are changing\n",
    "for images_batch,labels_batch in test_ds.take(1):\n",
    "    \n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    \n",
    "    print(\"first image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"first images's actual label:\",class_name[first_label])\n",
    "    \n",
    "    batch_prediction= model.predict(images_batch)\n",
    "    print(\"predicted label:\",class_name[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for batch data predictions\n",
    "def predict(model,img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array,0) #to create batch\n",
    "    \n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    \n",
    "    predicted_class = class_name[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for images,labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax=plt.subplot(3,3,i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        predicted_class,confidence=predict(model,images[i].numpy())\n",
    "        actual_class = class_name[labels[i]]\n",
    "        plt.title(f\"Actual :{actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdcc9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25631b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
